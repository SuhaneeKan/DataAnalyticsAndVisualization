{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AIM** :Getting introduced to data analytics libraries in Python and R"
      ],
      "metadata": {
        "id": "PtzZocB5UHqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task to be performed** : Exploring top 5 Python libraries\n",
        "\n",
        "1.TensorFlow\n",
        "\n",
        "2.NumPy\n",
        "\n",
        "3.SciPy\n",
        "\n",
        "4.Pandas\n",
        "\n",
        "5.PyTorch\n"
      ],
      "metadata": {
        "id": "Xgm515iUWUpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorFlow:**\n",
        "\n",
        "Purpose: Deep learning library for building and training neural network models.\n",
        "\n",
        "Features: Flexible architecture, GPU support, extensive community, and high-level interfaces like Keras.\n",
        "\n",
        "Use Cases: Neural networks, machine learning models, and deep learning applications."
      ],
      "metadata": {
        "id": "rDTvzjwiYYjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow\n",
        "!pip install tensorflow\n",
        "\n",
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Dummy dataset\n",
        "X_train = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y_train = [0, 1, 1, 0]\n",
        "\n",
        "# Build a simple neural network\n",
        "model = Sequential([\n",
        "    Dense(4, input_dim=2, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=500, verbose=2)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_train)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLGfM7mbYTSy",
        "outputId": "e29b4557-19ae-4ff1-d84d-dbf2a04d77c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Epoch 1/500\n",
            "1/1 - 1s - loss: 0.7716 - accuracy: 0.5000 - 901ms/epoch - 901ms/step\n",
            "Epoch 2/500\n",
            "1/1 - 0s - loss: 0.7707 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 3/500\n",
            "1/1 - 0s - loss: 0.7697 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 4/500\n",
            "1/1 - 0s - loss: 0.7688 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 5/500\n",
            "1/1 - 0s - loss: 0.7679 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 6/500\n",
            "1/1 - 0s - loss: 0.7670 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 7/500\n",
            "1/1 - 0s - loss: 0.7660 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 8/500\n",
            "1/1 - 0s - loss: 0.7651 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 9/500\n",
            "1/1 - 0s - loss: 0.7642 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 10/500\n",
            "1/1 - 0s - loss: 0.7633 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 11/500\n",
            "1/1 - 0s - loss: 0.7625 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 12/500\n",
            "1/1 - 0s - loss: 0.7616 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 13/500\n",
            "1/1 - 0s - loss: 0.7607 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 14/500\n",
            "1/1 - 0s - loss: 0.7598 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 15/500\n",
            "1/1 - 0s - loss: 0.7590 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 16/500\n",
            "1/1 - 0s - loss: 0.7581 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 17/500\n",
            "1/1 - 0s - loss: 0.7573 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 18/500\n",
            "1/1 - 0s - loss: 0.7564 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 19/500\n",
            "1/1 - 0s - loss: 0.7556 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 20/500\n",
            "1/1 - 0s - loss: 0.7547 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 21/500\n",
            "1/1 - 0s - loss: 0.7539 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 22/500\n",
            "1/1 - 0s - loss: 0.7531 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 23/500\n",
            "1/1 - 0s - loss: 0.7523 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 24/500\n",
            "1/1 - 0s - loss: 0.7515 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 25/500\n",
            "1/1 - 0s - loss: 0.7507 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 26/500\n",
            "1/1 - 0s - loss: 0.7499 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 27/500\n",
            "1/1 - 0s - loss: 0.7491 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 28/500\n",
            "1/1 - 0s - loss: 0.7483 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 29/500\n",
            "1/1 - 0s - loss: 0.7475 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 30/500\n",
            "1/1 - 0s - loss: 0.7468 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 31/500\n",
            "1/1 - 0s - loss: 0.7460 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 32/500\n",
            "1/1 - 0s - loss: 0.7453 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 33/500\n",
            "1/1 - 0s - loss: 0.7445 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 34/500\n",
            "1/1 - 0s - loss: 0.7438 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 35/500\n",
            "1/1 - 0s - loss: 0.7430 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 36/500\n",
            "1/1 - 0s - loss: 0.7423 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 37/500\n",
            "1/1 - 0s - loss: 0.7416 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 38/500\n",
            "1/1 - 0s - loss: 0.7409 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 39/500\n",
            "1/1 - 0s - loss: 0.7401 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 40/500\n",
            "1/1 - 0s - loss: 0.7394 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 41/500\n",
            "1/1 - 0s - loss: 0.7387 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 42/500\n",
            "1/1 - 0s - loss: 0.7380 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 43/500\n",
            "1/1 - 0s - loss: 0.7373 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 44/500\n",
            "1/1 - 0s - loss: 0.7367 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 45/500\n",
            "1/1 - 0s - loss: 0.7360 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 46/500\n",
            "1/1 - 0s - loss: 0.7353 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 47/500\n",
            "1/1 - 0s - loss: 0.7346 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 48/500\n",
            "1/1 - 0s - loss: 0.7340 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 49/500\n",
            "1/1 - 0s - loss: 0.7333 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 50/500\n",
            "1/1 - 0s - loss: 0.7327 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 51/500\n",
            "1/1 - 0s - loss: 0.7320 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 52/500\n",
            "1/1 - 0s - loss: 0.7314 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 53/500\n",
            "1/1 - 0s - loss: 0.7308 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 54/500\n",
            "1/1 - 0s - loss: 0.7301 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 55/500\n",
            "1/1 - 0s - loss: 0.7295 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 56/500\n",
            "1/1 - 0s - loss: 0.7289 - accuracy: 0.2500 - 22ms/epoch - 22ms/step\n",
            "Epoch 57/500\n",
            "1/1 - 0s - loss: 0.7283 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 58/500\n",
            "1/1 - 0s - loss: 0.7277 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 59/500\n",
            "1/1 - 0s - loss: 0.7270 - accuracy: 0.2500 - 20ms/epoch - 20ms/step\n",
            "Epoch 60/500\n",
            "1/1 - 0s - loss: 0.7264 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 61/500\n",
            "1/1 - 0s - loss: 0.7258 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 62/500\n",
            "1/1 - 0s - loss: 0.7253 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 63/500\n",
            "1/1 - 0s - loss: 0.7247 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 64/500\n",
            "1/1 - 0s - loss: 0.7241 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 65/500\n",
            "1/1 - 0s - loss: 0.7235 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 66/500\n",
            "1/1 - 0s - loss: 0.7229 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 67/500\n",
            "1/1 - 0s - loss: 0.7224 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 68/500\n",
            "1/1 - 0s - loss: 0.7218 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 69/500\n",
            "1/1 - 0s - loss: 0.7212 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 70/500\n",
            "1/1 - 0s - loss: 0.7207 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 71/500\n",
            "1/1 - 0s - loss: 0.7201 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 72/500\n",
            "1/1 - 0s - loss: 0.7196 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 73/500\n",
            "1/1 - 0s - loss: 0.7190 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 74/500\n",
            "1/1 - 0s - loss: 0.7185 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 75/500\n",
            "1/1 - 0s - loss: 0.7179 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 76/500\n",
            "1/1 - 0s - loss: 0.7174 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 77/500\n",
            "1/1 - 0s - loss: 0.7169 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 78/500\n",
            "1/1 - 0s - loss: 0.7163 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 79/500\n",
            "1/1 - 0s - loss: 0.7158 - accuracy: 0.2500 - 17ms/epoch - 17ms/step\n",
            "Epoch 80/500\n",
            "1/1 - 0s - loss: 0.7153 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 81/500\n",
            "1/1 - 0s - loss: 0.7147 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 82/500\n",
            "1/1 - 0s - loss: 0.7142 - accuracy: 0.2500 - 21ms/epoch - 21ms/step\n",
            "Epoch 83/500\n",
            "1/1 - 0s - loss: 0.7137 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 84/500\n",
            "1/1 - 0s - loss: 0.7132 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 85/500\n",
            "1/1 - 0s - loss: 0.7127 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 86/500\n",
            "1/1 - 0s - loss: 0.7122 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 87/500\n",
            "1/1 - 0s - loss: 0.7117 - accuracy: 0.2500 - 22ms/epoch - 22ms/step\n",
            "Epoch 88/500\n",
            "1/1 - 0s - loss: 0.7112 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 89/500\n",
            "1/1 - 0s - loss: 0.7107 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 90/500\n",
            "1/1 - 0s - loss: 0.7102 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 91/500\n",
            "1/1 - 0s - loss: 0.7097 - accuracy: 0.2500 - 17ms/epoch - 17ms/step\n",
            "Epoch 92/500\n",
            "1/1 - 0s - loss: 0.7092 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 93/500\n",
            "1/1 - 0s - loss: 0.7087 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 94/500\n",
            "1/1 - 0s - loss: 0.7082 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 95/500\n",
            "1/1 - 0s - loss: 0.7077 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 96/500\n",
            "1/1 - 0s - loss: 0.7073 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 97/500\n",
            "1/1 - 0s - loss: 0.7068 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 98/500\n",
            "1/1 - 0s - loss: 0.7063 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 99/500\n",
            "1/1 - 0s - loss: 0.7058 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 100/500\n",
            "1/1 - 0s - loss: 0.7054 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 101/500\n",
            "1/1 - 0s - loss: 0.7049 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 102/500\n",
            "1/1 - 0s - loss: 0.7044 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 103/500\n",
            "1/1 - 0s - loss: 0.7039 - accuracy: 0.2500 - 20ms/epoch - 20ms/step\n",
            "Epoch 104/500\n",
            "1/1 - 0s - loss: 0.7035 - accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 105/500\n",
            "1/1 - 0s - loss: 0.7030 - accuracy: 0.2500 - 22ms/epoch - 22ms/step\n",
            "Epoch 106/500\n",
            "1/1 - 0s - loss: 0.7025 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 107/500\n",
            "1/1 - 0s - loss: 0.7021 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 108/500\n",
            "1/1 - 0s - loss: 0.7016 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 109/500\n",
            "1/1 - 0s - loss: 0.7012 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 110/500\n",
            "1/1 - 0s - loss: 0.7007 - accuracy: 0.2500 - 17ms/epoch - 17ms/step\n",
            "Epoch 111/500\n",
            "1/1 - 0s - loss: 0.7003 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 112/500\n",
            "1/1 - 0s - loss: 0.6998 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 113/500\n",
            "1/1 - 0s - loss: 0.6994 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 114/500\n",
            "1/1 - 0s - loss: 0.6990 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 115/500\n",
            "1/1 - 0s - loss: 0.6985 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 116/500\n",
            "1/1 - 0s - loss: 0.6981 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 117/500\n",
            "1/1 - 0s - loss: 0.6977 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 118/500\n",
            "1/1 - 0s - loss: 0.6972 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 119/500\n",
            "1/1 - 0s - loss: 0.6968 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 120/500\n",
            "1/1 - 0s - loss: 0.6964 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 121/500\n",
            "1/1 - 0s - loss: 0.6960 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 122/500\n",
            "1/1 - 0s - loss: 0.6956 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 123/500\n",
            "1/1 - 0s - loss: 0.6951 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 124/500\n",
            "1/1 - 0s - loss: 0.6947 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 125/500\n",
            "1/1 - 0s - loss: 0.6943 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 126/500\n",
            "1/1 - 0s - loss: 0.6939 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 127/500\n",
            "1/1 - 0s - loss: 0.6935 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 128/500\n",
            "1/1 - 0s - loss: 0.6931 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 129/500\n",
            "1/1 - 0s - loss: 0.6927 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 130/500\n",
            "1/1 - 0s - loss: 0.6923 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 131/500\n",
            "1/1 - 0s - loss: 0.6918 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 132/500\n",
            "1/1 - 0s - loss: 0.6914 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 133/500\n",
            "1/1 - 0s - loss: 0.6910 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 134/500\n",
            "1/1 - 0s - loss: 0.6906 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 135/500\n",
            "1/1 - 0s - loss: 0.6902 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 136/500\n",
            "1/1 - 0s - loss: 0.6898 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 137/500\n",
            "1/1 - 0s - loss: 0.6895 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 138/500\n",
            "1/1 - 0s - loss: 0.6891 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 139/500\n",
            "1/1 - 0s - loss: 0.6887 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 140/500\n",
            "1/1 - 0s - loss: 0.6883 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 141/500\n",
            "1/1 - 0s - loss: 0.6879 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 142/500\n",
            "1/1 - 0s - loss: 0.6875 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 143/500\n",
            "1/1 - 0s - loss: 0.6871 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 144/500\n",
            "1/1 - 0s - loss: 0.6867 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 145/500\n",
            "1/1 - 0s - loss: 0.6863 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 146/500\n",
            "1/1 - 0s - loss: 0.6859 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 147/500\n",
            "1/1 - 0s - loss: 0.6856 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 148/500\n",
            "1/1 - 0s - loss: 0.6852 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 149/500\n",
            "1/1 - 0s - loss: 0.6848 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 150/500\n",
            "1/1 - 0s - loss: 0.6844 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 151/500\n",
            "1/1 - 0s - loss: 0.6840 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 152/500\n",
            "1/1 - 0s - loss: 0.6837 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 153/500\n",
            "1/1 - 0s - loss: 0.6833 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 154/500\n",
            "1/1 - 0s - loss: 0.6829 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 155/500\n",
            "1/1 - 0s - loss: 0.6825 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 156/500\n",
            "1/1 - 0s - loss: 0.6822 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 157/500\n",
            "1/1 - 0s - loss: 0.6818 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 158/500\n",
            "1/1 - 0s - loss: 0.6814 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 159/500\n",
            "1/1 - 0s - loss: 0.6811 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 160/500\n",
            "1/1 - 0s - loss: 0.6807 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 161/500\n",
            "1/1 - 0s - loss: 0.6803 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 162/500\n",
            "1/1 - 0s - loss: 0.6799 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 163/500\n",
            "1/1 - 0s - loss: 0.6796 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 164/500\n",
            "1/1 - 0s - loss: 0.6792 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 165/500\n",
            "1/1 - 0s - loss: 0.6788 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 166/500\n",
            "1/1 - 0s - loss: 0.6785 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 167/500\n",
            "1/1 - 0s - loss: 0.6781 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 168/500\n",
            "1/1 - 0s - loss: 0.6778 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 169/500\n",
            "1/1 - 0s - loss: 0.6774 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 170/500\n",
            "1/1 - 0s - loss: 0.6770 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 171/500\n",
            "1/1 - 0s - loss: 0.6767 - accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 172/500\n",
            "1/1 - 0s - loss: 0.6763 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 173/500\n",
            "1/1 - 0s - loss: 0.6759 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 174/500\n",
            "1/1 - 0s - loss: 0.6756 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 175/500\n",
            "1/1 - 0s - loss: 0.6752 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 176/500\n",
            "1/1 - 0s - loss: 0.6749 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 177/500\n",
            "1/1 - 0s - loss: 0.6745 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 178/500\n",
            "1/1 - 0s - loss: 0.6741 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 179/500\n",
            "1/1 - 0s - loss: 0.6738 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 180/500\n",
            "1/1 - 0s - loss: 0.6734 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 181/500\n",
            "1/1 - 0s - loss: 0.6731 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 182/500\n",
            "1/1 - 0s - loss: 0.6727 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 183/500\n",
            "1/1 - 0s - loss: 0.6724 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 184/500\n",
            "1/1 - 0s - loss: 0.6720 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 185/500\n",
            "1/1 - 0s - loss: 0.6717 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 186/500\n",
            "1/1 - 0s - loss: 0.6713 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 187/500\n",
            "1/1 - 0s - loss: 0.6709 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 188/500\n",
            "1/1 - 0s - loss: 0.6706 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 189/500\n",
            "1/1 - 0s - loss: 0.6702 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 190/500\n",
            "1/1 - 0s - loss: 0.6699 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 191/500\n",
            "1/1 - 0s - loss: 0.6695 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 192/500\n",
            "1/1 - 0s - loss: 0.6692 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 193/500\n",
            "1/1 - 0s - loss: 0.6688 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 194/500\n",
            "1/1 - 0s - loss: 0.6685 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 195/500\n",
            "1/1 - 0s - loss: 0.6681 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 196/500\n",
            "1/1 - 0s - loss: 0.6678 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 197/500\n",
            "1/1 - 0s - loss: 0.6674 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 198/500\n",
            "1/1 - 0s - loss: 0.6671 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 199/500\n",
            "1/1 - 0s - loss: 0.6667 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 200/500\n",
            "1/1 - 0s - loss: 0.6664 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 201/500\n",
            "1/1 - 0s - loss: 0.6660 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 202/500\n",
            "1/1 - 0s - loss: 0.6657 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 203/500\n",
            "1/1 - 0s - loss: 0.6654 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 204/500\n",
            "1/1 - 0s - loss: 0.6650 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 205/500\n",
            "1/1 - 0s - loss: 0.6647 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 206/500\n",
            "1/1 - 0s - loss: 0.6644 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 207/500\n",
            "1/1 - 0s - loss: 0.6640 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 208/500\n",
            "1/1 - 0s - loss: 0.6637 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 209/500\n",
            "1/1 - 0s - loss: 0.6633 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 210/500\n",
            "1/1 - 0s - loss: 0.6630 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 211/500\n",
            "1/1 - 0s - loss: 0.6627 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 212/500\n",
            "1/1 - 0s - loss: 0.6623 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 213/500\n",
            "1/1 - 0s - loss: 0.6620 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 214/500\n",
            "1/1 - 0s - loss: 0.6616 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 215/500\n",
            "1/1 - 0s - loss: 0.6613 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 216/500\n",
            "1/1 - 0s - loss: 0.6610 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 217/500\n",
            "1/1 - 0s - loss: 0.6606 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 218/500\n",
            "1/1 - 0s - loss: 0.6603 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 219/500\n",
            "1/1 - 0s - loss: 0.6600 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 220/500\n",
            "1/1 - 0s - loss: 0.6597 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 221/500\n",
            "1/1 - 0s - loss: 0.6593 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 222/500\n",
            "1/1 - 0s - loss: 0.6590 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 223/500\n",
            "1/1 - 0s - loss: 0.6587 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 224/500\n",
            "1/1 - 0s - loss: 0.6583 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 225/500\n",
            "1/1 - 0s - loss: 0.6580 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 226/500\n",
            "1/1 - 0s - loss: 0.6577 - accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 227/500\n",
            "1/1 - 0s - loss: 0.6573 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 228/500\n",
            "1/1 - 0s - loss: 0.6570 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 229/500\n",
            "1/1 - 0s - loss: 0.6567 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 230/500\n",
            "1/1 - 0s - loss: 0.6564 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 231/500\n",
            "1/1 - 0s - loss: 0.6560 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 232/500\n",
            "1/1 - 0s - loss: 0.6557 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 233/500\n",
            "1/1 - 0s - loss: 0.6554 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 234/500\n",
            "1/1 - 0s - loss: 0.6550 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 235/500\n",
            "1/1 - 0s - loss: 0.6547 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 236/500\n",
            "1/1 - 0s - loss: 0.6544 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 237/500\n",
            "1/1 - 0s - loss: 0.6541 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 238/500\n",
            "1/1 - 0s - loss: 0.6537 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 239/500\n",
            "1/1 - 0s - loss: 0.6534 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 240/500\n",
            "1/1 - 0s - loss: 0.6531 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 241/500\n",
            "1/1 - 0s - loss: 0.6528 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 242/500\n",
            "1/1 - 0s - loss: 0.6524 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 243/500\n",
            "1/1 - 0s - loss: 0.6521 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 244/500\n",
            "1/1 - 0s - loss: 0.6518 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 245/500\n",
            "1/1 - 0s - loss: 0.6514 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 246/500\n",
            "1/1 - 0s - loss: 0.6511 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 247/500\n",
            "1/1 - 0s - loss: 0.6508 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 248/500\n",
            "1/1 - 0s - loss: 0.6505 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 249/500\n",
            "1/1 - 0s - loss: 0.6501 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 250/500\n",
            "1/1 - 0s - loss: 0.6498 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 251/500\n",
            "1/1 - 0s - loss: 0.6495 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 252/500\n",
            "1/1 - 0s - loss: 0.6492 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 253/500\n",
            "1/1 - 0s - loss: 0.6488 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 254/500\n",
            "1/1 - 0s - loss: 0.6485 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 255/500\n",
            "1/1 - 0s - loss: 0.6482 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 256/500\n",
            "1/1 - 0s - loss: 0.6479 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 257/500\n",
            "1/1 - 0s - loss: 0.6476 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 258/500\n",
            "1/1 - 0s - loss: 0.6472 - accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 259/500\n",
            "1/1 - 0s - loss: 0.6469 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 260/500\n",
            "1/1 - 0s - loss: 0.6466 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 261/500\n",
            "1/1 - 0s - loss: 0.6463 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 262/500\n",
            "1/1 - 0s - loss: 0.6459 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 263/500\n",
            "1/1 - 0s - loss: 0.6456 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 264/500\n",
            "1/1 - 0s - loss: 0.6453 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 265/500\n",
            "1/1 - 0s - loss: 0.6450 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 266/500\n",
            "1/1 - 0s - loss: 0.6447 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 267/500\n",
            "1/1 - 0s - loss: 0.6443 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 268/500\n",
            "1/1 - 0s - loss: 0.6440 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 269/500\n",
            "1/1 - 0s - loss: 0.6437 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 270/500\n",
            "1/1 - 0s - loss: 0.6434 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 271/500\n",
            "1/1 - 0s - loss: 0.6431 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 272/500\n",
            "1/1 - 0s - loss: 0.6427 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 273/500\n",
            "1/1 - 0s - loss: 0.6424 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 274/500\n",
            "1/1 - 0s - loss: 0.6421 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 275/500\n",
            "1/1 - 0s - loss: 0.6418 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 276/500\n",
            "1/1 - 0s - loss: 0.6414 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 277/500\n",
            "1/1 - 0s - loss: 0.6411 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 278/500\n",
            "1/1 - 0s - loss: 0.6408 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 279/500\n",
            "1/1 - 0s - loss: 0.6405 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 280/500\n",
            "1/1 - 0s - loss: 0.6401 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 281/500\n",
            "1/1 - 0s - loss: 0.6398 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 282/500\n",
            "1/1 - 0s - loss: 0.6395 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 283/500\n",
            "1/1 - 0s - loss: 0.6392 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 284/500\n",
            "1/1 - 0s - loss: 0.6389 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 285/500\n",
            "1/1 - 0s - loss: 0.6385 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 286/500\n",
            "1/1 - 0s - loss: 0.6382 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 287/500\n",
            "1/1 - 0s - loss: 0.6379 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 288/500\n",
            "1/1 - 0s - loss: 0.6376 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 289/500\n",
            "1/1 - 0s - loss: 0.6372 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 290/500\n",
            "1/1 - 0s - loss: 0.6369 - accuracy: 0.5000 - 21ms/epoch - 21ms/step\n",
            "Epoch 291/500\n",
            "1/1 - 0s - loss: 0.6366 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 292/500\n",
            "1/1 - 0s - loss: 0.6363 - accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 293/500\n",
            "1/1 - 0s - loss: 0.6360 - accuracy: 0.5000 - 22ms/epoch - 22ms/step\n",
            "Epoch 294/500\n",
            "1/1 - 0s - loss: 0.6356 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 295/500\n",
            "1/1 - 0s - loss: 0.6353 - accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 296/500\n",
            "1/1 - 0s - loss: 0.6350 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 297/500\n",
            "1/1 - 0s - loss: 0.6347 - accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 298/500\n",
            "1/1 - 0s - loss: 0.6344 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 299/500\n",
            "1/1 - 0s - loss: 0.6340 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 300/500\n",
            "1/1 - 0s - loss: 0.6337 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 301/500\n",
            "1/1 - 0s - loss: 0.6334 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 302/500\n",
            "1/1 - 0s - loss: 0.6331 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 303/500\n",
            "1/1 - 0s - loss: 0.6327 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 304/500\n",
            "1/1 - 0s - loss: 0.6324 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 305/500\n",
            "1/1 - 0s - loss: 0.6321 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 306/500\n",
            "1/1 - 0s - loss: 0.6318 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 307/500\n",
            "1/1 - 0s - loss: 0.6314 - accuracy: 0.5000 - 21ms/epoch - 21ms/step\n",
            "Epoch 308/500\n",
            "1/1 - 0s - loss: 0.6311 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 309/500\n",
            "1/1 - 0s - loss: 0.6308 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 310/500\n",
            "1/1 - 0s - loss: 0.6305 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 311/500\n",
            "1/1 - 0s - loss: 0.6301 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 312/500\n",
            "1/1 - 0s - loss: 0.6298 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 313/500\n",
            "1/1 - 0s - loss: 0.6295 - accuracy: 0.5000 - 21ms/epoch - 21ms/step\n",
            "Epoch 314/500\n",
            "1/1 - 0s - loss: 0.6292 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 315/500\n",
            "1/1 - 0s - loss: 0.6288 - accuracy: 0.5000 - 28ms/epoch - 28ms/step\n",
            "Epoch 316/500\n",
            "1/1 - 0s - loss: 0.6285 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 317/500\n",
            "1/1 - 0s - loss: 0.6282 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 318/500\n",
            "1/1 - 0s - loss: 0.6279 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 319/500\n",
            "1/1 - 0s - loss: 0.6275 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 320/500\n",
            "1/1 - 0s - loss: 0.6272 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 321/500\n",
            "1/1 - 0s - loss: 0.6269 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 322/500\n",
            "1/1 - 0s - loss: 0.6266 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 323/500\n",
            "1/1 - 0s - loss: 0.6262 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 324/500\n",
            "1/1 - 0s - loss: 0.6259 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 325/500\n",
            "1/1 - 0s - loss: 0.6256 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 326/500\n",
            "1/1 - 0s - loss: 0.6253 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 327/500\n",
            "1/1 - 0s - loss: 0.6249 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 328/500\n",
            "1/1 - 0s - loss: 0.6246 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 329/500\n",
            "1/1 - 0s - loss: 0.6243 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 330/500\n",
            "1/1 - 0s - loss: 0.6240 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 331/500\n",
            "1/1 - 0s - loss: 0.6236 - accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 332/500\n",
            "1/1 - 0s - loss: 0.6233 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 333/500\n",
            "1/1 - 0s - loss: 0.6230 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 334/500\n",
            "1/1 - 0s - loss: 0.6227 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 335/500\n",
            "1/1 - 0s - loss: 0.6223 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 336/500\n",
            "1/1 - 0s - loss: 0.6220 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 337/500\n",
            "1/1 - 0s - loss: 0.6217 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 338/500\n",
            "1/1 - 0s - loss: 0.6214 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 339/500\n",
            "1/1 - 0s - loss: 0.6210 - accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 340/500\n",
            "1/1 - 0s - loss: 0.6207 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 341/500\n",
            "1/1 - 0s - loss: 0.6204 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 342/500\n",
            "1/1 - 0s - loss: 0.6200 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 343/500\n",
            "1/1 - 0s - loss: 0.6197 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 344/500\n",
            "1/1 - 0s - loss: 0.6194 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 345/500\n",
            "1/1 - 0s - loss: 0.6190 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 346/500\n",
            "1/1 - 0s - loss: 0.6187 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 347/500\n",
            "1/1 - 0s - loss: 0.6184 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 348/500\n",
            "1/1 - 0s - loss: 0.6180 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 349/500\n",
            "1/1 - 0s - loss: 0.6177 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 350/500\n",
            "1/1 - 0s - loss: 0.6174 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 351/500\n",
            "1/1 - 0s - loss: 0.6171 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 352/500\n",
            "1/1 - 0s - loss: 0.6167 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 353/500\n",
            "1/1 - 0s - loss: 0.6164 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 354/500\n",
            "1/1 - 0s - loss: 0.6161 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 355/500\n",
            "1/1 - 0s - loss: 0.6157 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 356/500\n",
            "1/1 - 0s - loss: 0.6154 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 357/500\n",
            "1/1 - 0s - loss: 0.6151 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 358/500\n",
            "1/1 - 0s - loss: 0.6147 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 359/500\n",
            "1/1 - 0s - loss: 0.6144 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 360/500\n",
            "1/1 - 0s - loss: 0.6141 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 361/500\n",
            "1/1 - 0s - loss: 0.6137 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 362/500\n",
            "1/1 - 0s - loss: 0.6134 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 363/500\n",
            "1/1 - 0s - loss: 0.6131 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 364/500\n",
            "1/1 - 0s - loss: 0.6127 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 365/500\n",
            "1/1 - 0s - loss: 0.6124 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 366/500\n",
            "1/1 - 0s - loss: 0.6121 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 367/500\n",
            "1/1 - 0s - loss: 0.6118 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 368/500\n",
            "1/1 - 0s - loss: 0.6114 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 369/500\n",
            "1/1 - 0s - loss: 0.6111 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 370/500\n",
            "1/1 - 0s - loss: 0.6108 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 371/500\n",
            "1/1 - 0s - loss: 0.6104 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 372/500\n",
            "1/1 - 0s - loss: 0.6101 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 373/500\n",
            "1/1 - 0s - loss: 0.6097 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 374/500\n",
            "1/1 - 0s - loss: 0.6094 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 375/500\n",
            "1/1 - 0s - loss: 0.6091 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 376/500\n",
            "1/1 - 0s - loss: 0.6087 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 377/500\n",
            "1/1 - 0s - loss: 0.6084 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 378/500\n",
            "1/1 - 0s - loss: 0.6080 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 379/500\n",
            "1/1 - 0s - loss: 0.6077 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 380/500\n",
            "1/1 - 0s - loss: 0.6074 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 381/500\n",
            "1/1 - 0s - loss: 0.6070 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 382/500\n",
            "1/1 - 0s - loss: 0.6067 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 383/500\n",
            "1/1 - 0s - loss: 0.6064 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 384/500\n",
            "1/1 - 0s - loss: 0.6060 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 385/500\n",
            "1/1 - 0s - loss: 0.6057 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 386/500\n",
            "1/1 - 0s - loss: 0.6053 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 387/500\n",
            "1/1 - 0s - loss: 0.6050 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 388/500\n",
            "1/1 - 0s - loss: 0.6047 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 389/500\n",
            "1/1 - 0s - loss: 0.6043 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 390/500\n",
            "1/1 - 0s - loss: 0.6040 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 391/500\n",
            "1/1 - 0s - loss: 0.6036 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 392/500\n",
            "1/1 - 0s - loss: 0.6033 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 393/500\n",
            "1/1 - 0s - loss: 0.6029 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 394/500\n",
            "1/1 - 0s - loss: 0.6026 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 395/500\n",
            "1/1 - 0s - loss: 0.6023 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 396/500\n",
            "1/1 - 0s - loss: 0.6019 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 397/500\n",
            "1/1 - 0s - loss: 0.6016 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 398/500\n",
            "1/1 - 0s - loss: 0.6012 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 399/500\n",
            "1/1 - 0s - loss: 0.6009 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 400/500\n",
            "1/1 - 0s - loss: 0.6006 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 401/500\n",
            "1/1 - 0s - loss: 0.6002 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 402/500\n",
            "1/1 - 0s - loss: 0.5999 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 403/500\n",
            "1/1 - 0s - loss: 0.5995 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 404/500\n",
            "1/1 - 0s - loss: 0.5992 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 405/500\n",
            "1/1 - 0s - loss: 0.5988 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 406/500\n",
            "1/1 - 0s - loss: 0.5985 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 407/500\n",
            "1/1 - 0s - loss: 0.5982 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 408/500\n",
            "1/1 - 0s - loss: 0.5978 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 409/500\n",
            "1/1 - 0s - loss: 0.5975 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 410/500\n",
            "1/1 - 0s - loss: 0.5971 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 411/500\n",
            "1/1 - 0s - loss: 0.5968 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 412/500\n",
            "1/1 - 0s - loss: 0.5964 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 413/500\n",
            "1/1 - 0s - loss: 0.5961 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 414/500\n",
            "1/1 - 0s - loss: 0.5957 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 415/500\n",
            "1/1 - 0s - loss: 0.5954 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 416/500\n",
            "1/1 - 0s - loss: 0.5950 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 417/500\n",
            "1/1 - 0s - loss: 0.5947 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 418/500\n",
            "1/1 - 0s - loss: 0.5943 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 419/500\n",
            "1/1 - 0s - loss: 0.5940 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 420/500\n",
            "1/1 - 0s - loss: 0.5936 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 421/500\n",
            "1/1 - 0s - loss: 0.5933 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 422/500\n",
            "1/1 - 0s - loss: 0.5929 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 423/500\n",
            "1/1 - 0s - loss: 0.5926 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 424/500\n",
            "1/1 - 0s - loss: 0.5922 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 425/500\n",
            "1/1 - 0s - loss: 0.5919 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 426/500\n",
            "1/1 - 0s - loss: 0.5915 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 427/500\n",
            "1/1 - 0s - loss: 0.5912 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 428/500\n",
            "1/1 - 0s - loss: 0.5908 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 429/500\n",
            "1/1 - 0s - loss: 0.5905 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 430/500\n",
            "1/1 - 0s - loss: 0.5901 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 431/500\n",
            "1/1 - 0s - loss: 0.5898 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 432/500\n",
            "1/1 - 0s - loss: 0.5894 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 433/500\n",
            "1/1 - 0s - loss: 0.5891 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 434/500\n",
            "1/1 - 0s - loss: 0.5887 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 435/500\n",
            "1/1 - 0s - loss: 0.5883 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 436/500\n",
            "1/1 - 0s - loss: 0.5880 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 437/500\n",
            "1/1 - 0s - loss: 0.5876 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 438/500\n",
            "1/1 - 0s - loss: 0.5873 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 439/500\n",
            "1/1 - 0s - loss: 0.5869 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 440/500\n",
            "1/1 - 0s - loss: 0.5866 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 441/500\n",
            "1/1 - 0s - loss: 0.5862 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 442/500\n",
            "1/1 - 0s - loss: 0.5858 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 443/500\n",
            "1/1 - 0s - loss: 0.5855 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 444/500\n",
            "1/1 - 0s - loss: 0.5851 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 445/500\n",
            "1/1 - 0s - loss: 0.5848 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 446/500\n",
            "1/1 - 0s - loss: 0.5844 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 447/500\n",
            "1/1 - 0s - loss: 0.5840 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 448/500\n",
            "1/1 - 0s - loss: 0.5837 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 449/500\n",
            "1/1 - 0s - loss: 0.5833 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 450/500\n",
            "1/1 - 0s - loss: 0.5830 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 451/500\n",
            "1/1 - 0s - loss: 0.5826 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 452/500\n",
            "1/1 - 0s - loss: 0.5822 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 453/500\n",
            "1/1 - 0s - loss: 0.5819 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 454/500\n",
            "1/1 - 0s - loss: 0.5815 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 455/500\n",
            "1/1 - 0s - loss: 0.5812 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 456/500\n",
            "1/1 - 0s - loss: 0.5808 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 457/500\n",
            "1/1 - 0s - loss: 0.5804 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 458/500\n",
            "1/1 - 0s - loss: 0.5801 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 459/500\n",
            "1/1 - 0s - loss: 0.5797 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 460/500\n",
            "1/1 - 0s - loss: 0.5793 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 461/500\n",
            "1/1 - 0s - loss: 0.5790 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 462/500\n",
            "1/1 - 0s - loss: 0.5786 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 463/500\n",
            "1/1 - 0s - loss: 0.5782 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 464/500\n",
            "1/1 - 0s - loss: 0.5779 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 465/500\n",
            "1/1 - 0s - loss: 0.5775 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 466/500\n",
            "1/1 - 0s - loss: 0.5771 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 467/500\n",
            "1/1 - 0s - loss: 0.5768 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 468/500\n",
            "1/1 - 0s - loss: 0.5764 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 469/500\n",
            "1/1 - 0s - loss: 0.5760 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 470/500\n",
            "1/1 - 0s - loss: 0.5757 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 471/500\n",
            "1/1 - 0s - loss: 0.5753 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 472/500\n",
            "1/1 - 0s - loss: 0.5749 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 473/500\n",
            "1/1 - 0s - loss: 0.5745 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 474/500\n",
            "1/1 - 0s - loss: 0.5742 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 475/500\n",
            "1/1 - 0s - loss: 0.5738 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 476/500\n",
            "1/1 - 0s - loss: 0.5734 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 477/500\n",
            "1/1 - 0s - loss: 0.5731 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 478/500\n",
            "1/1 - 0s - loss: 0.5727 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 479/500\n",
            "1/1 - 0s - loss: 0.5723 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 480/500\n",
            "1/1 - 0s - loss: 0.5720 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 481/500\n",
            "1/1 - 0s - loss: 0.5716 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 482/500\n",
            "1/1 - 0s - loss: 0.5712 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 483/500\n",
            "1/1 - 0s - loss: 0.5708 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 484/500\n",
            "1/1 - 0s - loss: 0.5705 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 485/500\n",
            "1/1 - 0s - loss: 0.5701 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 486/500\n",
            "1/1 - 0s - loss: 0.5697 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 487/500\n",
            "1/1 - 0s - loss: 0.5693 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 488/500\n",
            "1/1 - 0s - loss: 0.5690 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 489/500\n",
            "1/1 - 0s - loss: 0.5686 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 490/500\n",
            "1/1 - 0s - loss: 0.5682 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 491/500\n",
            "1/1 - 0s - loss: 0.5678 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 492/500\n",
            "1/1 - 0s - loss: 0.5674 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 493/500\n",
            "1/1 - 0s - loss: 0.5671 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 494/500\n",
            "1/1 - 0s - loss: 0.5667 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 495/500\n",
            "1/1 - 0s - loss: 0.5663 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 496/500\n",
            "1/1 - 0s - loss: 0.5659 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 497/500\n",
            "1/1 - 0s - loss: 0.5655 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 498/500\n",
            "1/1 - 0s - loss: 0.5652 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 499/500\n",
            "1/1 - 0s - loss: 0.5648 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 500/500\n",
            "1/1 - 0s - loss: 0.5644 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Predictions: [[0.50939596]\n",
            " [0.7207829 ]\n",
            " [0.4933297 ]\n",
            " [0.3994638 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy:**\n",
        "\n",
        "Purpose: Numerical computing library for handling large, multi-dimensional arrays and matrices.\n",
        "\n",
        "Features: Efficient operations, mathematical functions, and linear algebra capabilities.\n",
        "\n",
        "Use Cases: Scientific computing, data analysis, and machine learning."
      ],
      "metadata": {
        "id": "e1vZjTXwZB9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Print the array\n",
        "print(\"Original Array:\")\n",
        "print(arr)\n",
        "\n",
        "# Perform some operations\n",
        "sum_rows = np.sum(arr, axis=1)\n",
        "mean_cols = np.mean(arr, axis=0)\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nSum of Rows:\")\n",
        "print(sum_rows)\n",
        "print(\"\\nMean of Columns:\")\n",
        "print(mean_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY-TWExKd4gC",
        "outputId": "4e857a48-013b-4e96-9fb7-dd622be35e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Array:\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "Sum of Rows:\n",
            "[ 6 15 24]\n",
            "\n",
            "Mean of Columns:\n",
            "[4. 5. 6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SciPy:**\n",
        "\n",
        "Purpose: Extension of NumPy, providing additional scientific computing tools and algorithms.\n",
        "\n",
        "Features: Integration, optimization, signal processing, statistical functions, and more.\n",
        "\n",
        "Use Cases: Scientific and technical computing, data analysis, and research."
      ],
      "metadata": {
        "id": "CKq93Rh1ZQ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate some sample data\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(50)\n",
        "y = 2 * x + 1 + 0.1 * np.random.randn(50)\n",
        "\n",
        "# Perform linear regression using SciPy\n",
        "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Slope: {slope}\")\n",
        "print(f\"Intercept: {intercept}\")\n",
        "print(f\"R-squared value: {r_value**2}\")\n",
        "\n",
        "# Plot the data and regression line\n",
        "plt.scatter(x, y, label='Data')\n",
        "plt.plot(x, slope * x + intercept, color='red', label='Linear Regression')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "HQNhXrDneIGJ",
        "outputId": "b3f1b7f5-3b3f-44bc-9f25-62142af9c4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope: 1.9776566003853095\n",
            "Intercept: 1.0096689274468886\n",
            "R-squared value: 0.9749140085676857\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pandas:**\n",
        "\n",
        "Purpose: Data manipulation and analysis library for structured data using DataFrame structures.\n",
        "\n",
        "Features: Data cleaning, transformation, analysis, and integration with other data formats.\n",
        "\n",
        "Use Cases: Data preprocessing, exploratory data analysis, and handling structured data."
      ],
      "metadata": {
        "id": "Nk5Rejb7Ztup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Create a simple DataFrame\n",
        "data = {\n",
        "    'Name': ['John', 'Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 22, 28, 35],\n",
        "    'City': ['New York', 'San Francisco', 'Chicago', 'Los Angeles', 'Seattle']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Perform basic operations\n",
        "print(\"\\nOperations:\")\n",
        "print(\"Mean Age:\", df['Age'].mean())\n",
        "print(\"City with the most occurrences:\", df['City'].mode()[0])\n",
        "\n",
        "# Filter the DataFrame\n",
        "print(\"\\nFiltered DataFrame:\")\n",
        "filtered_df = df[df['Age'] > 25]\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwvc9trOeRVw",
        "outputId": "bb195197-648e-4953-c141-0821f283631c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name  Age           City\n",
            "0     John   25       New York\n",
            "1    Alice   30  San Francisco\n",
            "2      Bob   22        Chicago\n",
            "3  Charlie   28    Los Angeles\n",
            "4    David   35        Seattle\n",
            "\n",
            "Operations:\n",
            "Mean Age: 28.0\n",
            "City with the most occurrences: Chicago\n",
            "\n",
            "Filtered DataFrame:\n",
            "      Name  Age           City\n",
            "1    Alice   30  San Francisco\n",
            "3  Charlie   28    Los Angeles\n",
            "4    David   35        Seattle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch:**\n",
        "\n",
        "Purpose: Open-source machine learning library for building and training deep learning models.\n",
        "\n",
        "Features: Dynamic computational graph, GPU support, and seamless deployment on mobile devices.\n",
        "\n",
        "Use Cases: Deep learning research, computer vision, natural language processing, and reinforcement learning."
      ],
      "metadata": {
        "id": "GU0yLjZCaTYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple neural network class\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# Dummy dataset\n",
        "X_train = torch.randn((100, 5))  # 100 samples, 5 features\n",
        "y_train = torch.randint(0, 2, (100, 1)).float()  # Binary classification\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = SimpleNN(input_size=5, hidden_size=10, output_size=1)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the trained model\n",
        "X_test = torch.randn((10, 5))  # 10 samples for testing\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = model(X_test)\n",
        "    print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqOOr35VeZn5",
        "outputId": "02240e7c-5e83-4ed4-bd25-14336de20f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.6828\n",
            "Epoch [200/1000], Loss: 0.6709\n",
            "Epoch [300/1000], Loss: 0.6626\n",
            "Epoch [400/1000], Loss: 0.6558\n",
            "Epoch [500/1000], Loss: 0.6499\n",
            "Epoch [600/1000], Loss: 0.6445\n",
            "Epoch [700/1000], Loss: 0.6396\n",
            "Epoch [800/1000], Loss: 0.6355\n",
            "Epoch [900/1000], Loss: 0.6318\n",
            "Epoch [1000/1000], Loss: 0.6285\n",
            "Predictions: tensor([[ 1.2317],\n",
            "        [ 0.0971],\n",
            "        [-0.4220],\n",
            "        [-0.4154],\n",
            "        [ 0.3068],\n",
            "        [ 0.0592],\n",
            "        [ 0.5253],\n",
            "        [ 0.4070],\n",
            "        [ 0.7234],\n",
            "        [-0.1429]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Task to be performed** : Exploring top 5 R libraries:\n",
        "\n",
        "1.dplyr\n",
        "\n",
        "2.tidyr\n",
        "\n",
        "3.stringr\n",
        "\n",
        "4.ggplot2\n",
        "\n",
        "5.lubridate"
      ],
      "metadata": {
        "id": "rjxLIjS7coXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**dplyr:**\n",
        "\n",
        "Purpose: R package for grammar of data manipulation.\n",
        "\n",
        "Features: Filtering, grouping, summarizing, and joining data frames.\n",
        "\n",
        "Use Cases: Common tasks in data wrangling and analysis."
      ],
      "metadata": {
        "id": "Q3XVroTscwe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and load the dplyr library\n",
        "install.packages(\"dplyr\")\n",
        "library(dplyr)\n",
        "\n",
        "# Create a sample dataframe\n",
        "data <- data.frame(\n",
        "  ID = c(1, 2, 3, 4, 5),\n",
        "  Name = c(\"John\", \"Alice\", \"Bob\", \"Charlie\", \"David\"),\n",
        "  Age = c(25, 30, 22, 28, 35)\n",
        ")\n",
        "\n",
        "# Use dplyr functions to filter and select data\n",
        "result <- data %>%\n",
        "  filter(Age > 25) %>%\n",
        "  select(ID, Name)\n",
        "\n",
        "# Print the result\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHod4qSIerHq",
        "outputId": "9c9f02a6-e645-4096-bc29-0c3130cb58c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ID    Name\n",
            "1  2   Alice\n",
            "2  4 Charlie\n",
            "3  5   David\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tidyr:**\n",
        "\n",
        "Purpose: Reshaping and tidying data in R.\n",
        "\n",
        "Features: Gather, spread, separate, and unite functions for data restructuring.\n",
        "\n",
        "Use Cases: Preparing data for analysis or visualization."
      ],
      "metadata": {
        "id": "IZGyehdZc3DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the tidyverse package\n",
        "install.packages(\"tidyverse\")\n",
        "\n",
        "# Load the tidyverse library\n",
        "library(tidyverse)\n",
        "\n",
        "# Create a sample dataframe with messy data\n",
        "messy_data <- data.frame(\n",
        "  Name = c(\"John\", \"Alice\", \"Bob\", \"Charlie\"),\n",
        "  Age = c(\"25\", \"30\", \"22\", \"unknown\"),\n",
        "  Score = c(\"A\", \"B\", \"C\", \"missing\")\n",
        ")\n",
        "\n",
        "# Print the messy data\n",
        "print(\"Messy Data:\")\n",
        "print(messy_data)\n",
        "\n",
        "# Use tidyr to clean and tidy the data\n",
        "tidy_data <- messy_data %>%\n",
        "  mutate(Age = as.numeric(ifelse(Age == \"unknown\", NA, Age)),\n",
        "         Score = factor(Score, levels = c(\"A\", \"B\", \"C\")))\n",
        "\n",
        "# Print the tidy data\n",
        "print(\"Tidy Data:\")\n",
        "print(tidy_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a7uAZU0gHcf",
        "outputId": "d0f4ab9d-d5e2-4c42-9751-b6fa61c6174d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Messy Data:\"\n",
            "     Name     Age   Score\n",
            "1    John      25       A\n",
            "2   Alice      30       B\n",
            "3     Bob      22       C\n",
            "4 Charlie unknown missing\n",
            "[1] \"Tidy Data:\"\n",
            "     Name Age Score\n",
            "1    John  25     A\n",
            "2   Alice  30     B\n",
            "3     Bob  22     C\n",
            "4 Charlie  NA  <NA>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**stringr:**\n",
        "\n",
        "Purpose: R package for string manipulation.\n",
        "\n",
        "Features: Consistent and user-friendly string operations.\n",
        "\n",
        "Use Cases: Cleaning and extracting information from text data."
      ],
      "metadata": {
        "id": "FG1BM5Hhc8JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the stringr package\n",
        "install.packages(\"stringr\")\n",
        "\n",
        "# Load the stringr library\n",
        "library(stringr)\n",
        "\n",
        "# Example usage of stringr functions\n",
        "text <- \"Hello, World! This is a sample string.\"\n",
        "\n",
        "# Extract words containing the letter 'o'\n",
        "result <- str_extract_all(text, \"\\\\b\\\\w*o\\\\w*\\\\b\")\n",
        "\n",
        "# Flatten the result list\n",
        "result <- unlist(result)\n",
        "\n",
        "# Print the result\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7ZGYN01g-4g",
        "outputId": "0f863232-ba9d-4300-cc61-563b6fd11cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Hello\" \"World\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ggplot2:**\n",
        "\n",
        "Purpose: Powerful R package for creating graphics and visualizations.\n",
        "\n",
        "Features: Grammar of graphics, versatile plotting system.\n",
        "\n",
        "Use Cases: Complex and informative data visualizations in data analysis and reporting."
      ],
      "metadata": {
        "id": "HN_vkPB8c-WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required package\n",
        "install.packages(\"ggplot2\")\n",
        "\n",
        "# Load the ggplot2 library\n",
        "library(ggplot2)\n",
        "\n",
        "# Create a sample dataframe\n",
        "data <- data.frame(\n",
        "  X = c(1, 2, 3, 4, 5),\n",
        "  Y = c(10, 8, 6, 4, 2)\n",
        ")\n",
        "\n",
        "# Create a basic scatter plot\n",
        "ggplot(data, aes(x = X, y = Y)) +\n",
        "  geom_point() +\n",
        "  labs(title = \"Simple Scatter Plot\", x = \"X-axis\", y = \"Y-axis\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "0kjd1G1VVDwq",
        "outputId": "aa20c7cf-3bd7-4e8f-c544-e0cb39f195e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plot without title"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC+lBMVEUAAAABAQECAgIDAwME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\ngP8Pi+MO1qTjxV8AAAAASUVORK5CYII="
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lubridate:**\n",
        "\n",
        "- **Purpose:** R package for easy date and time manipulation.\n",
        "- **Features:** Simple parsing, intuitive manipulation, easy extraction, time intervals handling, time zone support, and date formatting.\n",
        "- **Use Cases:** Ideal for data analysis, financial modeling, and any task involving date and time in R."
      ],
      "metadata": {
        "id": "qXTo-mHPhfv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the lubridate package (if not already installed)\n",
        "if (!requireNamespace(\"lubridate\", quietly = TRUE)) {\n",
        "  install.packages(\"lubridate\")\n",
        "}\n",
        "\n",
        "# Load the lubridate library\n",
        "library(lubridate)\n",
        "\n",
        "# Create a sample date object\n",
        "date_object <- as.Date(\"2022-01-16\")\n",
        "\n",
        "# Print the original date\n",
        "print(\"Original Date:\")\n",
        "print(date_object)\n",
        "\n",
        "# Add one month to the date\n",
        "new_date <- date_object %m+% months(1)\n",
        "\n",
        "# Print the updated date\n",
        "print(\"Updated Date (added one month):\")\n",
        "print(new_date)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XatJrx7bUVRD",
        "outputId": "601ea04b-1a73-42dc-8389-5a5209206294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Original Date:\"\n",
            "[1] \"2022-01-16\"\n",
            "[1] \"Updated Date (added one month):\"\n",
            "[1] \"2022-02-16\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:** Identified the Data Analytics Libraries in Python and R\n",
        "\n",
        "Performed simple experiments with these libraries in Python and R"
      ],
      "metadata": {
        "id": "ufUhVw3un17f"
      }
    }
  ]
}